[{"body":"#### Recommended way to type-hint pandas dataframes / series\n\nHi,\n\nI'm new to using pandera. I originally came to it because it allowed me to specify more precise dtypes such as `pdt.Series[bool]`, which is nice.\n\nHowever, I am unsure about best practices around this.\n\nI kind of expected the following minimal example to work, but it does not:\n\n```python\nimport pandera.typing as pdt\nimport pandas as pd\n\ndef myfun(df: pdt.DataFrame):\n    pass\n\ndf = pd.DataFrame({'a': [0, 1], 'b': [3, 4]})\nmyfun(df)\n```\n\nThis gives me an \"Argument of type \"DataFrame\" cannot be assigned to parameter \"df\" of type \"DataFrame[Unknown]\" in function \"myfun\" error in the last line.\n\nWhat is the recommended way to annotate dataframe / series types? What am I missing?\n\n(This is with pandera 0.24.0, pandas 2.2.3.)","comments":[{"id":"IC_kwDOCUcGo86sFsiw","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"hi @e-pet so `pandera.pandas.typing` (formerly `pandera.typing`) for pandas DataFrame annotation needs to be used together with a `DataFrameModel` subclass. It can't be used just by itself (hence the type linting error you're seeing).\n\nIf you want to annotate just a dataframe without a pandera DataFrameModel, just use straight-up `pandas.DataFrame`.","createdAt":"2025-05-16T16:24:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/2002#issuecomment-2887174320","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86sFvNm","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"Also, with `pandera.pandas.typing.Series`, it's really only meant to be used in the `DataFrameModel` if you want to be super explicit:\n\n```python\nimport pandera.pandas as pa\nimport pandera.pandas.typing as pat\n\nclass DFModel(pa.DataFrameModel):\n    col1: pat.Series[bool]\n    col2: pat.Series[int]\n    ...  # etc\n```\n\nIt doesn't really do anything when used in a function type annotation:\n\n```python\ndef fn(seres: pat.Series[int]): ...\n```","createdAt":"2025-05-16T16:29:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/2002#issuecomment-2887185254","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86sKRGv","author":{"login":"e-pet"},"authorAssociation":"NONE","body":"Hi @cosmicBboy, thank you for the quick response!\n\nWell, of course, my minimal example was too minimal - as usual. ;-) At some point in my code, I would like to precisely annotate the type of a Series, i.e., `Series[bool]` or `Series[int]` etc. This is apparently not possible with the standard pandas types (\"pd.Series[bool]: TypeError: 'type' object is not subscriptable\"), but it worked (as in: the parser does not complain) with `pandera.typing.Series`. I then proceeded to just swap out all pd types for pdt types throughout my code base for consistency, which led to the issue mentioned above when I finally pass in an actual pandas dataframe.\n\nFollowing your suggestion, I have now changed back all `pdt.DataFrame` type annotations to `pd.DataFrame` while keeping the `pdt.Series[dtype]` ones. That still produces some '\"pandas.core.series.Series\" is not assignable to \"pandera.typing.pandas.Series\" errors, however, obviously paralleling the DataFrame issue.\n\nAs to \"it doesn't really do anything\" - what do you mean by this? My type checker parses this as expected, produces errors when series types are inconsistent, etc.?\n\nMy takeaway then is: while I _can_ technically annotate `pdt.Series[bool]` etc., it does not really \"work\" and thus is not recommended...?\n\nBy the way, I cannot import `pandera.pandas.typing` on 0.24.0, is that expected? There is `pandera.typing.pandas`, however, which is being used.\n\n![Image](https://github.com/user-attachments/assets/72e6c474-4394-4311-879f-49e10fa1e5e5)","createdAt":"2025-05-17T12:55:47Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/2002#issuecomment-2888372655","viewerDidAuthor":false}],"number":2002,"title":"Best practice type hints"},{"body":"My experience for the first 2 minutes trying Pandera:\n\n1. Trying out the [example](https://colab.research.google.com/github/unionai-oss/pandera/blob/main/docs/source/notebooks/try_pandera.ipynb) in Colab linked on the main documentation page: First cell fails..\n\n![Image](https://github.com/user-attachments/assets/948c7c32-53c2-43c7-80f9-a2c2bde98e3f)\n\n2. Ok, maybe its the new think they announce in a big banner on the main page:\n\n![Image](https://github.com/user-attachments/assets/3b208064-04d9-4200-b07a-ebad1d9e4154)\n\nhttps://github.com/unionai-oss/pandera/releases/tag/v0.24.0\n\n![Image](https://github.com/user-attachments/assets/f16073bb-2f84-4c24-953d-d715879b2a31)\n\n😒\n\n\n\n\n","comments":[{"id":"IC_kwDOCUcGo86r1NIO","author":{"login":"turbotimon"},"authorAssociation":"NONE","body":"Workarounds:\n\nEither\n\n```\n!pip install pandera==\"0.24.0rc0\"\n```\n\nor for version <0.24 get an older version of the Notebook:\nhttps://github.com/unionai-oss/pandera/blob/35295d314828df62301430e4427116ddc2b516d2/docs/source/notebooks/try_pandera.ipynb \n","createdAt":"2025-05-15T07:32:48Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/2001#issuecomment-2882851342","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86r4Oy7","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"apologies @turbotimon, this should be addressed when I cut the 0.24.0 release (today or tomorrow)","createdAt":"2025-05-15T12:28:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/unionai-oss/pandera/issues/2001#issuecomment-2883644603","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86r4oS9","author":{"login":"turbotimon"},"authorAssociation":"NONE","body":"Thanks, guess I've chosen just a bad moment to take a look at Pandera 😅","createdAt":"2025-05-15T13:06:16Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/2001#issuecomment-2883749053","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86r5Kb0","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"don't be discouraged! yes this following release makes a somewhat large change to the way folks install/import the pandera pandas schemas.","createdAt":"2025-05-15T13:49:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/2001#issuecomment-2883888884","viewerDidAuthor":false}],"number":2001,"title":"[Feedback/Docu BUG] Not a good \"getting started\" experience"},{"body":"https://github.com/unionai-oss/pandera/blob/7725a6361ff6c55c5b446aee09f119cc82307527/README.md?plain=1#L41-L50\n\n```cmd\n(.venv) c:\\apps\\astToolkit\\toolFactory>pip install 'pandera[pandas]'\nERROR: Invalid requirement: \"'pandera[pandas]'\": Expected package name at the start of dependency specifier\n    'pandera[pandas]'\n    ^\n\n(.venv) c:\\apps\\astToolkit\\toolFactory>pip install pandera[pandas]  \nCollecting pandera[pandas]\n  Downloading pandera-0.23.1-py3-none-any.whl.metadata (18 kB)\nWARNING: pandera 0.23.1 does not provide the extra 'pandas'\n```","comments":[{"id":"IC_kwDOCUcGo86rwfoV","author":{"login":"hunterhogan"},"authorAssociation":"NONE","body":"srsly?\n\n```cmd\n(.venv) c:\\apps\\astToolkit\\toolFactory>pip install pandera[all] \n\n...\n\n      Successfully uninstalled pandera-0.23.1\nSuccessfully installed MarkupSafe-3.0.2 attrs-25.3.0 black-25.1.0 chardet-5.2.0 click-8.1.8 frictionless-5.18.1 humanize-4.12.3 hypothesis-6.131.17 isodate-0.7.2 jinja2-3.1.6 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 markdown-it-py-3.0.0 marko-2.1.3 mdurl-0.1.2 pandera-0.7.2 pathspec-0.12.1 petl-1.7.16 python-slugify-8.0.4 referencing-0.36.2 rfc3986-2.0.0 rich-14.0.0 rpds-py-0.24.0 shellingham-1.5.4 simpleeval-1.0.3 sortedcontainers-2.4.0 tabulate-0.9.0 text-unidecode-1.3 typer-0.15.4 validators-0.35.0\n\n```\n\n## starting over\n\ninstall new venv\n\n```cmd\n(.venv) C:\\apps\\astToolkit>py -V\nPython 3.13.3\n\n(.venv) C:\\apps\\astToolkit>py -m pip install -U pip\n...\nSuccessfully installed pip-25.1.1\n\n(.venv) C:\\apps\\astToolkit>pip install -e .[testing] -e .\\toolFactory pandera\n...\n\n(.venv) C:\\apps\\astToolkit>pip list\nPackage            Version     Editable project location\n------------------ ----------- ------------------------------\nannotated-types    0.7.0\nastToolkit         0.2.3       C:\\apps\\astToolkit\nautoflake          2.3.1\ncffi               1.17.1\ncharset-normalizer 3.4.2\ncolorama           0.4.6\ncoverage           7.8.0\nexecnet            2.1.1\niniconfig          2.1.0\nllvmlite           0.44.0\nmore-itertools     10.7.0\nmypy               1.15.0\nmypy_extensions    1.1.0\nnumba              0.61.2\nnumpy              2.2.5\npackaging          25.0\npandas             2.2.3\npandera            0.23.1\npip                25.1.1\npluggy             1.5.0\npycparser          2.22\npydantic           2.11.4\npydantic_core      2.33.2\npyflakes           3.3.2\npytest             8.3.5\npytest-cov         6.1.1\npytest-xdist       3.6.1\npython-dateutil    2.9.0.post0\npython_minifier    2.11.3\npytz               2025.2\npyupgrade          3.19.1\nresampy            0.4.3\nscipy              1.15.2\nsix                1.17.0\nsoundfile          0.13.1\ntokenize_rt        6.1.0\ntomli              2.2.1\ntoolFactory        0.0.1       C:\\apps\\astToolkit\\toolFactory\ntqdm               4.67.1\ntrove-classifiers  2025.5.9.12\ntypeguard          4.4.2\ntyping_extensions  4.13.2\ntyping-inspect     0.9.0\ntyping-inspection  0.4.0\ntzdata             2025.2\nZ0Z_tools          0.10.15\n```\n\nNo errors or warnings. \npandera            0.23.1","createdAt":"2025-05-14T21:24:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1999#issuecomment-2881616405","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86rxDyZ","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"The pandas extra is not available yet. It comes out in version 0.24.0","createdAt":"2025-05-14T22:47:33Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1999#issuecomment-2881764505","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86r527H","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"apologies for the snafu there, there was a momentary mismatch between README/Docs instructions and the latest available release. `0.24.0` should now be out: https://github.com/unionai-oss/pandera/releases/tag/v0.24.0","createdAt":"2025-05-15T14:39:38Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/unionai-oss/pandera/issues/1999#issuecomment-2884071111","viewerDidAuthor":false}],"number":1999,"title":"pip"},{"body":"This is a very specific situation, but the refactor from [this pr](https://github.com/unionai-oss/pandera/pull/1883) introduced a bug when decorating methods.\n\nI believe that change added a check meant to ensure the arguments were aligned in methods if the `self` was somehow omitted, but if exactly one of the arguments is passed by name then that code is executed and the arguments end up misaligned, so the validation occurs on the wrong value.\n\nThe reported error is `E       pandera.errors.BackendNotFoundError: Backend not found for backend, class:`\nBut the reason is the incorrect type of the object being looked up.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n\n#### Code Sample, a copy-pastable example\n\n```python\nclass Example:\n    @pa.check_io(a=pa.DataFrameModel.to_schema(), out=pa.DataFrameModel.to_schema())\n    def example_method(self, a: pd.DataFrame, b: str) -> pd.DataFrame:\n        return a\n\nexample = Example()\nexample.example_method(pd.Dataframe(), b=\"\")\n```\nError:\n```\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/ec2-user/git/core/.pixi/envs/default/lib/python3.11/site-packages/pandera/decorators.py\", line 524, in _wrapper\n    return wrapped_fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ec2-user/git/core/.pixi/envs/default/lib/python3.11/site-packages/pandera/decorators.py\", line 429, in _wrapper\n    out = wrapped(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ec2-user/git/core/.pixi/envs/default/lib/python3.11/site-packages/pandera/decorators.py\", line 258, in _wrapper\n    pos_args[obj_getter] = schema.validate(\n                           ^^^^^^^^^^^^^^^^\n  File \"/home/ec2-user/git/core/.pixi/envs/default/lib/python3.11/site-packages/pandera/api/pandas/container.py\", line 126, in validate\n    return self._validate(\n           ^^^^^^^^^^^^^^^\n  File \"/home/ec2-user/git/core/.pixi/envs/default/lib/python3.11/site-packages/pandera/api/pandas/container.py\", line 147, in _validate\n    return self.get_backend(check_obj).validate(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ec2-user/git/core/.pixi/envs/default/lib/python3.11/site-packages/pandera/api/base/schema.py\", line 125, in get_backend\n    raise BackendNotFoundError(\npandera.errors.BackendNotFoundError: Backend not found for backend, class: (<class 'pandera.api.pandas.container.DataFrameSchema'>, <class '__main__.Example'>). Looked up the following base classes: (<class '__main__.Example'>, <class 'object'>)\n```\n\n#### Expected behavior\nThe means of passing arguments to methods (positional or named) not to matter for the decorators)\n\n#### Desktop (please complete the following information):\n\n - OS: Linux\n\n#### Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n#### Additional context\nAdd any other context about the problem here.\n","comments":[{"id":"IC_kwDOCUcGo86sHLKH","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"ah, lemme take a look","createdAt":"2025-05-16T19:53:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1997#issuecomment-2887561863","viewerDidAuthor":false}],"number":1997,"title":"check_io/check_input/check_output decorators failing"},{"body":"**Describe the bug**\n`pandera.io.from_frictionless_schema` throws an error when reading a frictionless schema in pandera==0.23.1 and frictionless==5.18.1\n\n\n- [ x]  I have checked that this issue has not already been reported.\n- [ x ] I have confirmed this bug exists on the latest version of pandera.\n- [ x ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport frictionless\nimport pandera\nfrom pandera.io import from_frictionless_schema\nexample_schema = frictionless.Schema.from_descriptor(\n    {\n        \"fields\": [\n            {\"name\": \"id\", \"type\": \"string\", \"description\":\"My Id\", \"constrains\" : {\"unique\":True}},\n        ]\n    }\n)\nexample_schema.to_yaml(\"example_schema.yaml\")\nfrom_frictionless_schema(\"example_schema.yaml\").columns[\"osm_id\"].unique\n\n```\nthrows \n```\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[4], line 9\n      1 example_schema = frictionless.Schema.from_descriptor(\n      2     {\n      3         \"fields\": [\n   (...)      6     }\n      7 )\n      8 example_schema.to_yaml(\"example_schema.yaml\")\n----> 9 from_frictionless_schema(\"example_schema.yaml\").columns[\"osm_id\"].unique\n\nFile ~/issues/pandera/pandera/io/pandas_io.py:854, in from_frictionless_schema(schema)\n    849 if not isinstance(schema, FrictionlessSchema):\n    850     schema = FrictionlessSchema(schema)\n    852 assembled_schema = {\n    853     \"columns\": {\n--> 854         field.name: FrictionlessFieldParser(\n    855             field, schema.primary_key\n    856         ).to_pandera_column()\n    857         for field in schema.fields\n    858     },\n    859     \"index\": None,\n    860     \"checks\": None,\n    861     \"coerce\": True,\n    862     \"strict\": True,\n    863     # only set dataframe-level uniqueness if the frictionless primary\n    864     # key property specifies more than one field\n    865     \"unique\": (\n    866         None if len(schema.primary_key) == 1 else list(schema.primary_key)\n    867     ),\n    868 }\n    869 return deserialize_schema(assembled_schema)\n\nFile ~/issues/pandera/pandera/io/pandas_io.py:649, in FrictionlessFieldParser.__init__(self, field, primary_keys)\n    647 self.primary_keys = primary_keys\n    648 self.name = field.name\n--> 649 self.type = field.get(\"type\", \"string\")\n\nAttributeError: 'StringField' object has no attribute 'get'\n```\n\n#### Expected behavior\nNo error\n\nI know what to change to solve the issue, I will make a PR\n","comments":[],"number":1994,"title":"Error loading frictionless schema"},{"body":"**Describe the bug**\nThe error report doesn't show all schema violations. \n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [x] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandera as pa\nimport pandas as pd\nimport json \n\nclass TestSchema(pa.DataFrameModel):\n    a: int = pa.Field(ge=2)\n    b: str = pa.Field(isin=['x', 'y'])\n    c: bool = pa.Field()\n\n    class Config:\n        strict = True\n        coerce = True\n        add_missing_columns = True\n\ntest_df = pd.DataFrame(\n    data = {'b': ['x', 'y', 'z']}\n)\n\ntry: \n    TestSchema(test_df, lazy=True)\nexcept pa.errors.SchemaErrors as e:\n    print(json.dumps(e.message, indent=2))\n```\noutputs\n```\n{\n  \"DATA\": {\n    \"ADD_MISSING_COLUMN_NO_DEFAULT\": [\n      {\n        \"schema\": \"TestSchema\",\n        \"column\": \"TestSchema\",\n        \"check\": \"add_missing_has_default\",\n        \"error\": \"column 'a' in DataFrameSchema {'a': <Schema Column(name=a, type=DataType(int64))>, 'b': <Schema Column(name=b, type=DataType(str))>, 'c': <Schema Column(name=c, type=DataType(bool))>} requires a default value when non-nullable add_missing_columns is enabled\"\n      }\n    ],\n    \"DATAFRAME_CHECK\": [\n      {\n        \"schema\": \"TestSchema\",\n        \"column\": \"b\",\n        \"check\": \"isin(['x', 'y'])\",\n        \"error\": \"Column 'b' failed element-wise validator number 0: isin(['x', 'y']) failure cases: z\"\n      }\n    ]\n  }\n}\n```\n\n#### Expected behavior\nMy test dataframe violates all columns: column `a` is missing (and not nullable/no default value), column `b` has an invalid value, and column `c` is also missing. However, the fact that column `c` is missing is not caught/shown as a failure case. I would expect it to appear in lazy validation. \n\n\n - OS: linux\n- pandera version: 0.23.1\n- python version: 3.10.17\n","comments":[],"number":1993,"title":"not all schema check failures are reported in lazy validation"},{"body":"**Is your feature request related to a problem? Please describe.**\n\nCurrently there's no formatter configuration and my global formatter triggers when I have \"Format on Save\". This wouldn't happen if a file was checked in. In my opinion, this is good to do even if the defaults are used.\n\n","comments":[],"number":1991,"title":"Add ruff or black autoformatter configuration to the repo"},{"body":"**Describe the bug**\nA clear and concise description of what the bug is.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandera.polars as pa\nimport polars as pl\n\nschema = pa.DataFrameSchema(\n    {\n        \".*value.*\": pa.Column(\n            float,\n            checks=pa.Check.greater_than_or_equal_to(0.0),\n            nullable=False,\n            required=False,\n            regex=True,\n        ),\n    },\n)\n\ndf = pl.DataFrame(\n    {\n        \"some_value_column\": [-1.0, 1.0],\n    }\n)\n\nschema.validate(df)\n```\ndoes not raise `SchemaError` even if it should given the negative value. If I change `requried=True`, I get\n```sh\npandera.errors.SchemaError: Column '.*value.*' failed validator number 0: <Check greater_than_or_equal_to: greater_than_or_equal_to(0.0)> failure case examples: [{'some_value_column': -1.0}]\n```\n\nWith Pandas, both cases raise correctly:\n\n```python\nimport pandas as pd\nimport pandera as pa\n\ndefault = pa.DataFrameSchema(\n    {\n        \".*value.*\": pa.Column(\n            float,\n            checks=pa.Check.greater_than_or_equal_to(0.0),\n            nullable=False,\n            required=True, # or False\n            regex=True,\n        ),\n    },\n    strict=False,\n)\n\ndf = pd.DataFrame(\n    {\n        \"some_value_column\": [-1.0, 1.0],\n    }\n)\n\ndefault.validate(df)\n```\n```sh\npandera.errors.SchemaError: Column 'some_value_column' failed element-wise validator number 0: greater_than_or_equal_to(0.0) failure cases: -1.0\n```\n\n#### Expected behavior\n\nValidation for the `pl.DataFrame` should fail for the example data and schema regardless of the value specified in `required`. \n\n#### Desktop (please complete the following information):\n\n`pandera==0.23.1`\n\n","comments":[{"id":"IC_kwDOCUcGo86pH_vh","author":{"login":"LeeviLindgren"},"authorAssociation":"NONE","body":"@cosmicBboy thanks for the quick fix!","createdAt":"2025-04-29T04:52:30Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1990#issuecomment-2837445601","viewerDidAuthor":false}],"number":1990,"title":"Using regex columns in DataFrameSchema does not work for Polars backend"},{"body":"Thanks for maintaining pandera, it is an awesome package!\n\n**Is your feature request related to a problem? Please describe.**\n\nI would like to update the checks for a index column after the schema is created, i.e. similar to `update_column` but for the index instead:\n\n```python\nimport pandas as pd\nimport pandera as pa\nfrom pandera import Check\n\n# Step 1: Define an initial schema\nschema = pa.DataFrameSchema(\n    columns={\n        \"value\": pa.Column(int),\n    },\n    index=pa.Index(\n        int,\n        checks=Check.ge(0),  # initial check: index values must be >= 0\n        name=\"my_index\",\n    ),\n)\n\n# Example dataframe\ndf = pd.DataFrame({\"value\": [10, 20, 30]}, index=[0, 1, 2])\ndf.index.name = \"my_index\"\n\nschema.validate(df)\n\n# Step 2: Update the index column\n# ERROR: This throws an error because pandera cannot find the index name as a column\nschema = schema.update_column(\n    \"my_index\",\n    checks=[\n        Check.ge(0),  # index values must be >= 0\n        Check.le(100),  # index values must also be <= 100\n    ],\n)\n\nschema.validate(df)\n```\n\nCurrently the only way to do this is to `schema.reset_index().update_column(...).set_index([\"my_index\"])` which is cumbersome. \n\n","comments":[{"id":"IC_kwDOCUcGo86o6FNY","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"this feature makes sense @kdheepak !\n\nFor you or the community: please feel free to make a PR for this, happy to help review","createdAt":"2025-04-28T01:53:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1988#issuecomment-2833797976","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86o7bY9","author":{"login":"kdheepak"},"authorAssociation":"CONTRIBUTOR","body":"Thanks for the quick response! \n\nDo you think this functionality should be part of `update_column` itself? Or should it be a new function (like `update_index`)?","createdAt":"2025-04-28T06:50:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1988#issuecomment-2834150973","viewerDidAuthor":false}],"number":1988,"title":"Allow updating checks for index column"},{"body":"Pandera 0.17.2 seems to have a depdendency on `multimethod` but does not cap the dependency to `multimethod` versions below 2.0. In `multimethod` 2.0, they removed the `overload` class and this is now causing `ImportErrors` during runtime. I am using poetry 1.1.8 and Python 3.9\n\nI resolved this by pinning my `multimethod` version to `^1.9`.\n\n- [ ] I have checked that this issue has not already been reported.\n- [ ] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\n# Your code here\nn/a\n```\n\n#### Expected behavior\nI expected my Poetry dependency resolver to be aware of these dependency issues and only resolve a working `multimethod`\n\n#### Desktop (please complete the following information):\n\n - OS: Sequoia 15.3.1 (24D70)\n - Browser: Chrome\n - Version: \n\n#### Error Message\n\n17-Apr-2025 16:10:15 | Hint: make sure your test modules/packages have valid Python names.\n17-Apr-2025 16:10:15 | Traceback:\n17-Apr-2025 16:10:15 | src/service/core/utils/validators.py:4: in <module>\n17-Apr-2025 16:10:15 | import pandera as pa\n17-Apr-2025 16:10:15 | .venv/lib/python3.9/site-packages/pandera/__init__.py:4: in <module>\n17-Apr-2025 16:10:15 | import pandera.backends\n17-Apr-2025 16:10:15 | .venv/lib/python3.9/site-packages/pandera/backends/__init__.py:6: in <module>\n17-Apr-2025 16:10:15 | import pandera.backends.pandas\n17-Apr-2025 16:10:15 | .venv/lib/python3.9/site-packages/pandera/backends/pandas/__init__.py:13: in <module>\n17-Apr-2025 16:10:15 | from pandera.backends.pandas.checks import PandasCheckBackend\n17-Apr-2025 16:10:15 | .venv/lib/python3.9/site-packages/pandera/backends/pandas/checks.py:7: in <module>\n17-Apr-2025 16:10:15 | from multimethod import DispatchError, overload\n17-Apr-2025 16:10:15 | E   ImportError: cannot import name 'overload' from 'multimethod' \n\nI checked the poetry.lock files and see that there is explicit multimethod dependency version restrictions\n\n[[package]]\nname = \"pandera\"\nversion = \"0.17.2\"\ndescription = \"A light-weight and flexible data validation and testing tool for statistical data objects.\"\ncategory = \"main\"\noptional = false\npython-versions = \">=3.7\"\n\n[package.dependencies]\n**multimethod = \"*\"**\nnumpy = \">=1.19.0\"\npackaging = \">=20.0\"\npandas = \">=1.2.0\"\npydantic = \"*\"\ntypeguard = \">=3.0.2\"\ntyping-inspect = \">=0.6.0\"\nwrapt = \"*\"\n","comments":[{"id":"IC_kwDOCUcGo86oFWaX","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"Hi @F28L any reason you can't upgrade pandera to the latest version?","createdAt":"2025-04-22T03:32:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1968#issuecomment-2819974807","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86sF-Ze","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"multimethod was removed as a dependency in v0.22.0","createdAt":"2025-05-16T16:58:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1968#issuecomment-2887247454","viewerDidAuthor":false}],"number":1968,"title":"Pandera 0.17.2, MultiMethod library version is unrestricted"},{"body":"Currently, when using `DataFrameModel` in Pandera, VS Code's Pylance extension does not provide attribute autocompletion for DataFrame columns defined in the schema. This limitation hampers developer productivity and code readability.\n\n**Example:**\n\n```python\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport pandas as pd\nimport pandera as pa\nfrom pandera.typing import Series, DataFrame\n\n\nclass OrdersSchema(pa.DataFrameModel):\n    \"\"\"Schema for customer orders dataset.\"\"\"\n\n    OrderID: Series[int]\n    CustomerName: Series[str]\n    OrderDate: Series[datetime]\n    Product: Series[str]\n    Quantity: Series[int] = pa.Field(ge=1)\n    Price: Series[float]\n    Country: Series[pd.StringDtype]\n\n    class Config:\n        strict = True\n\n\n@pa.check_types(lazy=True)\ndef load_orders(path: Path) -> DataFrame[OrdersSchema]:\n    df = pd.read_csv(path)\n    return df\n\n\norders = load_orders(Path(\"orders.csv\"))\nprint(orders.Country)  # VS Code does not autocomplete 'Country'\n```\n\n\nIn the example above, despite defining the `Country` column in the `OrdersSchema`, VS Code does not offer autocompletion for `orders.Country`. This issue has been noted in previous discussions, such as Issue #1687, but remains unresolved.\n\n**Proposed Solution:**\n\nEnhance the integration between `DataFrameModel` and static type checkers like Pylance to support attribute autocompletion for DataFrame columns. This could involve providing additional type hints or leveraging existing Python typing mechanisms to make the schema's fields more discoverable by IDEs.\n\n**Benefits:**\n\n- Improved developer experience with better IDE support.\n- Enhanced code readability and maintainability.\n- Reduced likelihood of typographical errors in column names.\n\nThank you for considering this feature request.\n\n","comments":[],"number":1967,"title":"Enhance VS Code Autocompletion for DataFrameModel Columns"},{"body":"**Describe the bug**\nA clear and concise description of what the bug is.\n\n\n- [X] I have checked that this issue has not already been reported.\n- [X] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandas as pd\nimport pandera as pa\nimport pandera.typing as pat\n\nclass PanderaTestSchema(pa.DataFrameModel):\n\tcol_a: pat.Series[str] = pa.Field()\n\tcol_b: pat.Series[str] = pa.Field()\n\n@pa.check_types\ndef valid_schema_output() -> pat.DataFrame[PanderaTestSchema]:\n\treturn pd.DataFrame({\n\t\t\"col_a\": [\"a\", \"b\"],\n\t\t\"col_b\": [\"c\", \"d\"],\n\t})\n\n@pa.check_types\ndef invalid_schema_output() -> pat.DataFrame[PanderaTestSchema]:\n\treturn pd.DataFrame({\n\t\t\"col_a\": [\"a\", \"b\"],\n\t})\n\nvalid_schema_output()\ninvalid_schema_output()\n```\n\n#### Expected behavior\nA clear and concise description of what you expected to happen.\n\nRun the sample code with validation disabled using the environment variable:\n```shell\nPANDERA_VALIDATION_ENABLED=False python pandera_test.py \n```\nIn 0.22.1, this would exit without error, in 0.23.0, this errors with `PANDERA_VALIDATION_ENABLED` set to False\n\n#### Desktop (please complete the following information):\n\n - OS:  Linux orca 6.14.0-gentoo #2 SMP PREEMPT_RT Thu Apr 10 13:27:14 EDT 2025 x86_64 AMD Ryzen 9 9950X 16-Core Processor AuthenticAMD GNU/Linux\n - Browser: N/A\n - Version: pandera-0.23.1\n\n#### Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n#### Additional context\nAdd any other context about the problem here.\n","comments":[],"number":1966,"title":"PANDERA_VALIDATION_ENABLED=False no longer disables validation after 0.23.0"},{"body":"**Describe the bug**\nColumns with type `bool` cannot have `pd.NA` as a value, and coercion does not seem to work for them.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nclass Schema(DataFrameModel):\n    class Config:\n        coerce = True\n\n    mothballed: Series[bool] = Field(nullable=True)\n    \"Innactive but not fully retired\"\n```\n\nThis can contain either `True`, `False` or `pd.NA`.\n\nwithout coercion, I get\n\n`pandera.errors.SchemaError: expected series 'mothballed' to have type bool, got object`\n\nenabling coercion results in this error: \n\n```error\npandera.errors.SchemaError: Error while coercing 'mothballed' to type bool: Could not coerce <class 'pandas.core.series.Series'> data_container into type bool:\n     index failure_case\n0      145         <NA>\n1      146         <NA>\n2      148         <NA>\n3      149         <NA>\n4      225         <NA>\n..     ...          ...\n765  13917         <NA>\n766  13938         <NA>\n767  13939         <NA>\n768  14055         <NA>\n769  14140         <NA>\n\n[770 rows x 2 columns]\n\n```\n\n#### Expected behavior\nBoolean columns should be nullable.\nhttps://pandas.pydata.org/docs/user_guide/boolean.html\n\n\n#### Desktop (please complete the following information):\n\n - OS: Linux Fedora 41\n - Version: 0.23.1\n\n#### Logs\nLog for a different case\n\n[download_gem_coal.log](https://github.com/user-attachments/files/19704782/download_gem_coal.log)\n\n","comments":[{"id":"IC_kwDOCUcGo86m44hv","author":{"login":"Jarek-Rolski"},"authorAssociation":"CONTRIBUTOR","body":"Hi @irm-codebase \n\nIt is not a pandera bug. When pandera tries to convert column to `bool` type it is using [numpy astype](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html) method. Numpy method simply cannot convert pandas NA type. Also `bool`  and `boolean`  are two different types. \n\nYou need to declare column as `boolean` type to make it work e.g.\n```\nimport pandera as pa\nimport pandas as pd\n\nclass Schema(DataFrameModel):\n    class Config:\n        coerce = True\n\n    mothballed: Series[\"boolean\"] = Field(nullable=True)\n    mothballed_pa: Series[pa.BOOL] = Field(nullable=True)\n    mothballed_pd: Series[pd.BooleanDtype] = Field(nullable=True)\n\ndf = pd.DataFrame(data={\n    \"mothballed\": [None, True, pd.NA],\n    \"mothballed_pa\": [None, True, pd.NA],\n    \"mothballed_pd\": [None, True, pd.NA]\n    })\n\ndf_validated = Schema.validate(df)\n\ndf_validated.dtypes\n```\nWhat gives\n```\nmothballed       boolean\nmothballed_pa    boolean\nmothballed_pd    boolean\ndtype: object\n```\n","createdAt":"2025-04-13T12:15:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/unionai-oss/pandera/issues/1961#issuecomment-2799929455","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86m5HUa","author":{"login":"irm-codebase"},"authorAssociation":"NONE","body":"Understood, thank you!\nThen perhaps consider adding something explaining this to the documentation, if it isn't there already?\n\n`pd.NA` is native to pandas, and `pandera` kind of has it in the name (even if it's growing past it).\nI think other people will intuitively think this feature would be native to it.","createdAt":"2025-04-13T15:09:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1961#issuecomment-2799990042","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86oFWtf","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"This is somewhat discussed in the docs here https://pandera.readthedocs.io/en/stable/dtype_validation.html#supported-pandas-datatypes @irm-codebase, but please feel free to edit that part of the docs to make it clearer.","createdAt":"2025-04-22T03:33:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1961#issuecomment-2819976031","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86o4Cf5","author":{"login":"irm-codebase"},"authorAssociation":"NONE","body":"Nah, in that case I'd say I'm the one who missed that bit.\nThanks for the help!","createdAt":"2025-04-27T07:30:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1961#issuecomment-2833262585","viewerDidAuthor":false}],"number":1961,"title":"Bool columns do not support `pd.NA`"},{"body":"**Describe the bug**\nWhen I define a polars `DataFrameModel` with a field, and I set `Config.add_missing_columns` to `True`, validation inconsistently drops or keeps the columns that are not defined in the schema, depending on which columns were in the input.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n#### Code Sample, a copy-pastable example\n\nIf I run:\n```python\nimport polars as pl\nfrom pandera.polars import DataFrameModel, Field\nfrom pandera.typing import Series\n\n\nclass Schema(DataFrameModel):\n    a: Series[int] = Field(nullable=True)\n\n    class Config:\n        add_missing_columns = True\n\n\ndf = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\nprint(Schema.validate(df))\n\ndf = pl.DataFrame({\"b\": [4, 5, 6]})\nprint(Schema.validate(df))\n```\n\nI get:\n```\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 4   │\n│ 2   ┆ 5   │\n│ 3   ┆ 6   │\n└─────┴─────┘\nshape: (3, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ i64  │\n╞══════╡\n│ null │\n│ null │\n│ null │\n└──────┘\n```\n\nwhich drops the column `b` only if `a` is not provided.\n\n#### Expected behavior\nI expect the `b` column to be kept or dropped consistently, regardless of the input columns provided.\n\nE.g.:\n```\nshape: (3, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 4   │\n│ 2   ┆ 5   │\n│ 3   ┆ 6   │\n└─────┴─────┘\nshape: (3, 2)\n┌──────┬─────┐\n│ a    ┆ b   │\n│ ---  ┆ --- │\n│ null ┆ i64 │\n╞══════╪═════╡\n│ null ┆ 4   │\n│ null ┆ 5   │\n│ null ┆ 6   │\n└──────┴─────┘\n```\n\n#### Desktop (please complete the following information):\n\n - OS: Linux - Ubuntu 24.04\n - Python 3.12.8\n - pandera==0.23.1\n - polars==1.27.0\n - pydantic==2.11.3\n - pydantic-core==2.33.1","comments":[],"number":1960,"title":"Inconsistent column filtering behaviour in polars DataFrameModel when add_missing_columns=True"},{"body":"**Describe the bug**\n\nIf you define a schema expecting a nullable string column, then attempt to validate a dataframe with an integer column instead that contains all NaN values in it, schema validation will _not_ fail.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandas as pd\nimport pandera as pa\n\nschema = pa.DataFrameSchema({\"col\": pa.Column(str, nullable=True)})\n\n# no error, even though \"col\" is the wrong type!\nint_nan_df = pd.DataFrame({\"col\": pd.Series([pd.NA], dtype=\"Int64\")})\nschema.validate(int_nan_df)\n\n# raises SchemaError (as expected)\nint_df = pd.DataFrame({\"col\": pd.Series([123], dtype=\"Int64\")})\nschema.validate(int_df)\n```\n\n#### Expected behavior\nSchema validation should raise `SchemaError` on column dtype mismatch, regardless of whether the column contains all NaN values.\n\n#### Desktop (please complete the following information):\n\n - OS: MacOS 15.3.2\n- pandas: 2.2.3\n- pandera: 0.23.1\n\n#### Additional context\n\nThis issue does not occur if the expected dtype in the schema is something other than a string. For example:\n\n```python\nimport pandera as pa\nimport pandas as pd\n\nschema = pa.DataFrameSchema({\"col\": pa.Column(int, nullable=True)})\n\n# raises SchemaError (as expected)\nstr_null_df = pd.DataFrame({\"col\": pd.Series([None], dtype=str)})\nschema.validate(str_null_df)\n```","comments":[],"number":1959,"title":"Schema validation does not fail if column with wrong dtype has all NaN values"},{"body":"**Describe the bug**\nUsing the `pandera.polars` api, I expect SchemaErrors to be raised when a Column does not meet the checks requirements. This issue could be linked to [1659](https://github.com/unionai-oss/pandera/issues/1659) but I'm not 100% positive.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandera.polars as pa\nimport polars as pl\n\ndf = pl.DataFrame({\"price\": [8, 12, 10, 24, 20, 18]})\n\nvalidation_columns = {\n    \"price\": pa.Column(int, pa.Check.in_range(min_value=5, max_value=20)),\n}\n\nvalidation_schema = pa.DataFrameSchema(\n    drop_invalid_rows=True,\n    columns=validation_columns,\n)\n\ntry:\n    res = validation_schema.validate(df, lazy=True)\nexcept pa.errors.SchemaErrors as exc:\n    print(exc)\nprint(\"between prints\")\nprint(res)\n```\n\n#### Expected behavior\n- The row with price 24 should be dropped as is it right now, but the except clause should catch a SchemaErrors exception.\n\n#### Desktop (please complete the following information):\n\n - python 3.11.7\n - polars-lts-cpu 1.17.1\n - pandera 0.23.1\n","comments":[{"id":"IC_kwDOCUcGo86lMtt-","author":{"login":"josselinbp"},"authorAssociation":"NONE","body":"Is possible to get the expected results using this snippet, but it feels like a workaround\n```python\nvalidation_schema = pa.DataFrameSchema(coerce=True, strict=\"filter\", columns=validation_columns)\n# If using a Lazyframe, only columns type will be checked, always casting to DataFrame\ndf = frame if isinstance(frame, pl.DataFrame) else frame.collect()\ntry:\n    success_cases = validation_schema.validate(df, lazy=True).lazy()\nexcept pa.errors.SchemaErrors as exc:\n    failure_cases: pl.DataFrame = exc.failure_cases\n    data: pl.LazyFrame = exc.data\n    success_cases = data.with_row_index().join(failure_cases.lazy(), on=\"index\", how=\"anti\")\n```","createdAt":"2025-04-02T07:26:09Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1958#issuecomment-2771573630","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86lPWSF","author":{"login":"josselinbp"},"authorAssociation":"NONE","body":"After rereading the doc I might be insane, closing issue\nhttps://pandera.readthedocs.io/en/stable/drop_invalid_rows.html","createdAt":"2025-04-02T11:28:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1958#issuecomment-2772264069","viewerDidAuthor":false}],"number":1958,"title":"SchemaErrors not raised when `drop_invalid_rows=True` on polars DataFrame"},{"body":"**Describe the bug**\nA clear and concise description of what the bug is.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nfrom io import StringIO\nimport pandas as pd\nimport pandera as pa\nimport numpy as np\n\n# data to validate\njson_data = \"\"\"\n{\n    \"column1\": [1, 4, 0, 10, 9],\n    \"column2\": [-1.3, -1.4, -2.9, -10.1, -20.4],\n    \"column3\": [\"value_1\", \"value_2\", \"value_3\", \"value_2\", \"value_1\"],\n}\n\"\"\"\ndf = pd.read_json(StringIO(json_data))\n\n# define schema\nschema = pa.DataFrameSchema({\n    \"column1\": pa.Column(int),\n    \"column2\": pa.Column(float),\n    \"column3\": pa.Column(str),\n})\n\n\nclass MyModel(pa.DataFrameModel):\n    column1: np.int64 = pa.Field()\n    column2: np.float64 = pa.Field()\n    column3: np.string_ = pa.Field()\n\n\nmodeled_df = MyModel.validate(df)\nprint(modeled_df)\n\nprint(modeled_df[\"column1\"])\n#     ~~~~~~~~~~ \"__getitem__\" method not defined on type \"DataFrameBase[MyModel]\"\nprint(modeled_df.column1)\n#              ~~~~~~~~~ Cannot access attribute \"column1\" for class \"DataFrameBase[MyModel]\"\n#     Attribute \"column1\" is unknown\nschema_df = schema(df)\nprint(schema_df)\nprint(schema_df[\"column1\"])\n```\n\n#### Expected behavior\n\n\n#### Desktop (please complete the following information):\n\n - OS: MacOS 15.3.2\n - pyright: 1.1.396\n\n#### Screenshots\n\n![Image](https://github.com/user-attachments/assets/5453f61c-d872-43a1-ba8e-de64e80ab6be)\n\n#### Additional context\n\nI know Pandera supports mypy but we are using pyright instead, so I just report the issue and use schema to avoid linting errors instead. ","comments":[],"number":1957,"title":"Pyright error __getitem__ method not defined on type \"DataFrameBase[MyModel]\""},{"body":"I've been using pandera a lot recently and it's a great package, thanks!\n\nI have recently been upgrading from python 3.11.8 to 3.12.8 and notice that schema's are not checked in the same way. In particular, using `pa.typing.DataFrame[MySchema](df)` *does* raise a `SchemaError` in 3.11.8, but *not* in 3.12.8. \n\n## Code to reproduce\n```python\nimport sys\nimport pandas as pd\nimport pandera as pa\n\n\nclass MySchema(pa.DataFrameModel):\n  foo: int = pa.Field()\n\n\nprint(sys.version)\ndf = pd.DataFrame({'bar': [1, 2, 3]})  # Wrong column name\nprint(pa.typing.DataFrame[MySchema](df))\n```\n\n## Results\n### Run with 3.11.8\n```\n3.11.8\n\nTraceback (most recent call last):\n   File \"pa.py\", line 14, in <module>\n    print(pa.typing.DataFrame[MySchema](df))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/<embedded stdlib>/typing.py\", line 1277, in __call__\n  File \"pandera/typing/common.py\", line 179, in __setattr__\n    self.__dict__ = schema_model.validate(self).__dict__\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pandera/api/pandas/model.py\", line 306, in validate\n    cls.to_schema().validate(\n  File \"pandera/api/pandas/container.py\", line 366, in validate\n    return self._validate(\n           ^^^^^^^^^^^^^^^\n  File \"pandera/api/pandas/container.py\", line 395, in _validate\n    return self.get_backend(check_obj).validate(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pandera/backends/pandas/container.py\", line 97, in validate\n    error_handler = self.run_checks_and_handle_errors(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pandera/backends/pandas/container.py\", line 172, in run_checks_and_handle_errors\n    error_handler.collect_error(\n  File \"pandera/error_handlers.py\", line 38, in collect_error\n    raise schema_error from original_exc\npandera.errors.SchemaError: column 'foo' not in dataframe\n   bar\n0    1\n1    2\n2    3\n```\n\n### Run with 3.12.8\n```\n3.12.8\n\n   bar\n0    1\n1    2\n2    3\n```\n\n## Implication\nThis function will raise a `SchemaError` in 3.11.8, but run fine in 3.12.8:\n\n```python\n@pa.check_types\ndef my_function() -> pa.typing.DataFrame[MySchema]:\n  \"\"\"Returns a DataFrame with the wrong column name.\"\"\"\n  return pa.typing.DataFrame[MySchema](pd.DataFrame({'bar': [1, 2, 3]}))\n```\n\n## Questions\n1. How is this intended? Should `pa.typing.DataFrame[MySchema](df)` raise a `SchemaError` or not? \n2. How should the return line in the function above be written? A few options are:\n\n```python\n# Option A: raises SchemaError, but some type checkers complain about return types\nreturn pd.DataFrame({'bar': [1, 2, 3]})\n\n# Option B:\nreturn MySchema(pd.DataFrame({'bar': [1, 2, 3]}))\n\n# Option C: does not raise in 3.12.8\nreturn pa.typing.DataFrame[MySchema](pd.DataFrame({'bar': [1, 2, 3]}))\n```\n\nIs `Option B` the one we should use?","comments":[{"id":"IC_kwDOCUcGo86k5mRf","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"looks like a bug @ahilbers, will take a look","createdAt":"2025-03-31T15:16:19Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/unionai-oss/pandera/issues/1954#issuecomment-2766562399","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86pw12H","author":{"login":"axyb"},"authorAssociation":"NONE","body":"This is likely broken due to this change: https://github.com/python/cpython/pull/115213/files#diff-ddb987fca5f5df0c9a2f5521ed687919d70bb3d64eaeb8021f98833a2a716887\n","createdAt":"2025-05-02T21:30:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1954#issuecomment-2848152967","viewerDidAuthor":false}],"number":1954,"title":"How should we use `pa.typing.DataFrame[MySchema]` in python 3.12?"},{"body":"```python\nclass TestModel(DataFrameModel):\n    a: int\n\n    class Config:\n        drop_invalid_rows = True\n\n\ndf_test = pd.DataFrame({'a': [1, 1.1]})\nTestModel(df_test, lazy=True)\n```\n\n```\nFile [~/miniforge3/envs/ds-3.12/lib/python3.12/site-packages/pandera/backends/pandas/base.py:194], in PandasSchemaBackend.drop_invalid_rows(self, check_obj, error_handler)\n    192 errors = error_handler.schema_errors\n    193 for err in errors:\n--> 194     index_values = err.failure_cases[\"index\"]\n    195     if isinstance(check_obj.index, pd.MultiIndex):\n    196         # MultiIndex values are saved on the error as strings so need to be cast back\n    197         # to their original types\n    198         index_tuples = err.failure_cases[\"index\"].apply(eval)\n\nTypeError: string indices must be integers, not 'str'\n```\n\nSame with Clumn.validate and Schema.validate.\npandera==0.23.1\npandas==2.2.3","comments":[{"id":"IC_kwDOCUcGo86jfDO8","author":{"login":"n-splv"},"authorAssociation":"NONE","body":"Through debugger I see that err.failure_cases is just a string \"float64\"","createdAt":"2025-03-21T09:38:07Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1946#issuecomment-2742825916","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86mRtHS","author":{"login":"joejoinerr"},"authorAssociation":"NONE","body":"I'm seeing the same issue, also with the same versions.\n\npandera==0.23.1\npandas==2.2.3","createdAt":"2025-04-09T13:12:21Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1946#issuecomment-2789659090","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86m47Tp","author":{"login":"Jarek-Rolski"},"authorAssociation":"CONTRIBUTOR","body":"I have the same issue with pandera==0.23.1 and pandas==2.2.3 \nBut when I run the above example on the main branch, it works as expected. Probably the problem was fixed in the meantime.","createdAt":"2025-04-13T12:48:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1946#issuecomment-2799940841","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86n-UfI","author":{"login":"joejoinerr"},"authorAssociation":"NONE","body":"The example in the docs is showing the same error too:\n\nhttps://pandera.readthedocs.io/en/stable/drop_invalid_rows.html","createdAt":"2025-04-21T10:29:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1946#issuecomment-2818131912","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86oFReH","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"This was fixed in https://github.com/unionai-oss/pandera/pull/1926/commits/55238b25b8b3161a8b29d06416f56307af865ef2, as part of [this PR](https://github.com/unionai-oss/pandera/pull/1926), you can confirm by installing the development version of pandera.\n\nWill be cutting a new release at the end of week.","createdAt":"2025-04-22T03:13:31Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1946#issuecomment-2819954567","viewerDidAuthor":false}],"number":1946,"title":"drop_invalid_rows is broken"},{"body":"**Describe the bug**\nGot the error `TypeError: Data type 'Time' not understood by Engine.` when I tried to use `polars.Time` as a Data Type on a `DataFrameModel`\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [x] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nfrom pandera import DataFrameModel, Field\n\nfrom pandera.typing import Series\n\nfrom pandera.engines.polars_engine import Time\n\n# from polars import Time\n\n\nclass TimeDataModel(DataFrameModel):\n    time: Series[Time] = Field(nullable=False, coerce=True)\n\n\nif __name__ == \"__main__\":\n    TimeDataModel.to_schema()\n\n```\n\n#### Expected behavior\n\nGiven that `Time` is inside the supported Data Types, it should work as intended like any other type.\n\n#### Desktop (please complete the following information):\n\n - OS: Windows 10\n - Python: 3.12.9\n - pandera: 0.23.1\n - polars: 1.25.2\n\n#### Additional info\n\nError when using `pandera.engines.polars_engine.Time`:\n```\nTypeError: Data type 'Time' not understood by Engine.\n```\n\nError when using `polars.Time`:\n```\nTypeError: dtype 'Time' not understood\n```","comments":[{"id":"IC_kwDOCUcGo86lyHE8","author":{"login":"ksolarski"},"authorAssociation":"CONTRIBUTOR","body":"You need to import `DataFrameModel` from `pandera.polars` instead of `pandera` if your DataframeModel is using Polars data types or Polars engine. Editing your example, the following runs:\n```python3\nfrom pandera.polars import DataFrameModel, Field\n\nfrom pandera.typing import Series\n\nfrom pandera.engines.polars_engine import Time\n\n# from polars import Time\n\n\nclass TimeDataModel(DataFrameModel):\n    time: Series[Time] = Field(nullable=False, coerce=True)\n\n\nif __name__ == \"__main__\":\n    TimeDataModel.to_schema()\n\n```","createdAt":"2025-04-06T11:33:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1944#issuecomment-2781376828","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86mGEzy","author":{"login":"rhacs"},"authorAssociation":"NONE","body":"@ksolarski thanks for replying\n\nI was testing the workaround you gave me, but I couldn't make it work on my project, it was practically imploding, so I decided to try it independently.\n\nThis is the test file\n```py\nfrom pandera.polars import DataFrameModel, Field\nfrom pandera.typing import Series\n\nfrom pandera.engines.polars_engine import Time\n\nfrom pandas import DataFrame\n\n\nclass TestDataFrame(DataFrameModel):\n    time: Series[Time] = Field(nullable=False, coerce=False)\n    # time: Series[Time] = Field(nullable=False, coerce=True)\n\n\nif __name__ == '__main__':\n    test_data: DataFrame = DataFrame({\n        \"time\": [\"10:00\", \"11:00\", \"12:00\", \"13:00\"]\n    })\n\n    TestDataFrame.validate(test_data, lazy=True)\n\n```\n\nAnd this is the error I get\n```\nBackend not found for backend, class: (<class 'pandera.api.polars.container.DataFrameSchema'>, <class 'pandas.core.frame.DataFrame'>). \nLooked up the following base classes: (<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.generic.NDFrame'>, <class 'pandas.core.base.PandasObject'>, <class 'pandas.core.accessor.DirNamesMixin'>, <class 'pandas.core.indexing.IndexingMixin'>, <class 'pandas.core.arraylike.OpsMixin'>, <class 'object'>)\n```\n\nAlso tried to update the libraries in case I was missing something crucial, but the result is the same. I'm working with\n\n- python 3.12.9\n- pandera 0.23.1\n- polars 1.25.2","createdAt":"2025-04-08T14:17:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1944#issuecomment-2786610418","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86mHwt4","author":{"login":"ksolarski"},"authorAssociation":"CONTRIBUTOR","body":"You are trying to use `time` data type from Polars engine with Pandas dataframe. Pandas dataframe doesn't have support for `time` data type. You should use Polars instead:\n```python3\nfrom pandera.polars import DataFrameModel, Field\nfrom pandera.typing import Series\n\nfrom pandera.engines.polars_engine import Time\nfrom datetime import time\nfrom polars import DataFrame\n\n\nclass TestDataFrame(DataFrameModel):\n    time: Series[Time] = Field(nullable=False, coerce=False)\n\n\ntest_data: DataFrame = DataFrame(\n    {\"time\": [time(10, 00), time(11, 00), time(12, 00), time(13, 00)]},\n)\n\nTestDataFrame.validate(test_data, lazy=True)\n```","createdAt":"2025-04-08T16:38:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1944#issuecomment-2787052408","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86mhkGy","author":{"login":"rhacs"},"authorAssociation":"NONE","body":"@ksolarski \n\nThat did the trick, thanks for the insight\n\nI was using Pandas to read the file, gather the data and apply the validations using the data frame schema. Since everything was working so far, I thought the `DataFrame` from pandas was compatible with the one from polars\n\nThanks again, cheers\n","createdAt":"2025-04-10T14:32:33Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1944#issuecomment-2793816498","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86oFOwR","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"Closing issue, looks like this is addressed","createdAt":"2025-04-22T03:05:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1944#issuecomment-2819943441","viewerDidAuthor":false}],"number":1944,"title":"`polars.Time` not understood by Engine"},{"body":"**Describe the bug**\nIf you define a DataFrameModel with to_fromat configuration, check_types converts the input_argumet to a function from DataFrame to dictionary or list of dictionary. \n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandera as pa\nfrom pandera import DataFrameModel\nfrom pandera.typing import Series, DataFrame\nimport pandera as pa\nimport pandas as pd\n\nclass HouseFrameV1(DataFrameModel):\n    \"\"\"Original Dataframe schema.\"\"\"\n    LotFrontage: Series[float] = pa.Field(nullable=True, coerce=True)\n    LotArea: Series[float] = pa.Field(nullable=True, coerce=True)\n    YearBuilt: Series[int] = pa.Field(description=\"Year built. Have to prior 2024\", lt=2024, coerce=True)\n    SaleType: Series[str] = pa.Field(description=\"Sale type\", nullable=False, coerce=True)\n\nclass HouseFrameV2(HouseFrameV1):\n    \"\"\"Overwrite configurations for the schema. Just add to_format configuration.\"\"\"\n    class Config:\n        \"\"\"Overwrite configurations for the schema.\"\"\"\n        to_format = \"dict\"\n        to_format_kwargs = {\"orient\": \"records\"}\n\n\n@pa.check_types\ndef test_v1(df: DataFrame[HouseFrameV1]) -> float:\n    return df.LotFrontage.mean()\n\n@pa.check_types\ndef test_v2(df: DataFrame[HouseFrameV2]) -> float:\n    return df.LotFrontage.mean()\n\nif __name__ == \"__main__\":\n    df = pd.DataFrame(\n        {\n            \"LotFrontage\": [1, 2, 3],\n            \"LotArea\": [1, 2, 3],\n            \"YearBuilt\": [1, 2, 3],\n            \"SaleType\": [\"A\", \"B\", \"C\"],\n        }\n    )\n    df1 = HouseFrameV1(df)\n    df2 = HouseFrameV2(df)\n    print(test_v1(df1))\n    print(test_v2(df2))\n```\n\n#### Expected behavior\nI would expect two lines to be printed as below. \n2.0\n2.0\n\n#### Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n\n#### Additional context\nBelow is the console output. The first version `print(test_v1(df1))` generates the first result (2.0). The second print generates the error. \n```\n2.0\nTraceback (most recent call last):\n  File \"/Users/Ragrawa/ml_template/test.py\", line 41, in <module>\n    print(test_v2(df2))\n          ^^^^^^^^^^^^\n  File \"/Users/Ragrawa/Library/Caches/pypoetry/virtualenvs/ml-template-lU0zwj_A-py3.11/lib/python3.11/site-packages/pandera/decorators.py\", line 839, in _wrapper\n    out = wrapped(*validated_pos, **validated_kwd)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/Ragrawa/ml_template/test.py\", line 27, in test_v2\n    return df.LotFrontage.mean()\n           ^^^^^^^^^^^^^^\nAttributeError: 'list' object has no attribute 'LotFrontage'\n```\n","comments":[],"number":1942,"title":"Check type along with to_format changes DataFrame to list of dictionaries."},{"body":"My data comes from a spark query:\n`transform(split(features, ' '), x -> cast(x as int)) AS features_array`\n\nWith spark I can validate it like this:\n```python\nschema = DataFrameSchema(\n    columns={\n        \"features\": Column(T.ArrayType(T.IntegerType())),\n    }\n)\n```\nOnce I save this spark df to parquet and read it with pandas, I get this dtype:\n```python\n>df_pd.dtypes\nfeature   list<element: int32>[pyarrow]\n```\n\nAnd unfortunately there's no way (that I'm aware of) to validate such dataframe:\n```python\n{\n    \"feature\": pa.Column(\"list<element: int32>[pyarrow]\"),  # TypeError: data type 'list<element: int32>[pyarrow]' not understood\n    \"feature\": pa.Column(list[int]),  # schema error: expected list[int], got list<element: int32>[pyarrow]\n}\n```","comments":[{"id":"IC_kwDOCUcGo86iGnse","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"interesting! are you aware if pyarrow (or pandas or some other library) is able to parse those strings (`\"list<element: int32>[pyarrow]\"`) into the actual pyarrow-native types?","createdAt":"2025-03-13T02:35:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1941#issuecomment-2719644446","viewerDidAuthor":false}],"number":1941,"title":"Add support for pyarrow-backed arrays in Pandas"},{"body":"**Describe the bug**\nA clear and concise description of what the bug is.\n\n- [ x] I have checked that this issue has not already been reported.\n- [ x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandas as pd\nimport numpy as np\nimport pandera as pa\nfrom pandera import Field, DataFrameModel\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\n\n# Define the schema: expects 'time' to be np.float32 with coercion enabled.\nclass ToySchema(pa.DataFrameModel):\n    time: pa.typing.Series[np.float32] = Field(coerce=True)\n\ndef validate_df(idx, df):\n    \"\"\"\n    Validate the DataFrame using the ToySchema schema.\n    Return a message with the thread id and resulting dtype, or an error message.\n    \"\"\"\n    try:\n        # Validation should coerce 'time' from float64 to float32.\n        validated_df = ToySchema.validate(df)\n        return f\"Thread {idx}: success, dtype:\\n{validated_df.dtypes}\"\n    except Exception as e:\n        return f\"Thread {idx}: error: {e}\"\n\n\ndef test_single_thread():\n    # Create a DataFrame with \"time\" as float64.\n    df = pd.DataFrame({\"time\": np.array([1.0, 2.0, 3.0], dtype=np.float64)})\n    print(\"=== Single Thread Validation ===\")\n    print(\"Before validation:\", df.dtypes)\n    try:\n        validated_df = ToySchema.validate(df)\n        print(\"After validation:\", validated_df.dtypes)\n    except Exception as e:\n        print(\"Validation Error:\", e)\n\ndef test_multithreading():\n    # Create the same DataFrame.\n    df = pd.DataFrame({\"time\": np.array([1.0, 2.0, 3.0], dtype=np.float64)})\n    total = 8  # Number of validations to perform\n    n_jobs = 4  # Number of threads\n\n    print(\"\\n=== Multithreaded Validation with ProgressParallel ===\")\n    results = Parallel(n_jobs=n_jobs, prefer=\"threads\")(\n        delayed(validate_df)(i, df) for i in range(total)\n    )\n    for res in results:\n        print(res)\n\nif __name__ == \"__main__\":\n    print(\"Pandera version:\")\n    print(pa.__version__)\n    test_single_thread()\n    test_multithreading()\n\n```\n\n#### Expected behavior\nSchema validation with coertion fails to cast float64 to float32 with pandas backend. It's not deterministic. Next, I've pasted the results of running the above script 3 times. Pandera version should be 0.23.1 but you deleted it from the version file\n```\n(tinyvit) jmt@jmtcluster:~/Projects/panama/panama-external$ python3 debug_multiprocessing.py \nPandera version:\n0.0.0+dev0\n=== Single Thread Validation ===\nBefore validation: time    float64\ndtype: object\nAfter validation: time    float32\ndtype: object\n\n=== Multithreaded Validation with ProgressParallel ===\nThread 0: success, dtype:\ntime    float32\ndtype: object\nThread 1: success, dtype:\ntime    float32\ndtype: object\nThread 2: success, dtype:\ntime    float32\ndtype: object\nThread 3: success, dtype:\ntime    float32\ndtype: object\nThread 4: error: expected series 'time' to have type float32, got float64\nThread 5: error: expected series 'time' to have type float32, got float64\nThread 6: error: expected series 'time' to have type float32, got float64\nThread 7: error: expected series 'time' to have type float32, got float64\n(tinyvit) jmt@jmtcluster:~/Projects/panama/panama-external$ python3 debug_multiprocessing.py \nPandera version:\n0.0.0+dev0\n=== Single Thread Validation ===\nBefore validation: time    float64\ndtype: object\nAfter validation: time    float32\ndtype: object\n\n=== Multithreaded Validation with ProgressParallel ===\nThread 0: success, dtype:\ntime    float32\ndtype: object\nThread 1: success, dtype:\ntime    float32\ndtype: object\nThread 2: success, dtype:\ntime    float32\ndtype: object\nThread 3: success, dtype:\ntime    float32\ndtype: object\nThread 4: success, dtype:\ntime    float32\ndtype: object\nThread 5: success, dtype:\ntime    float32\ndtype: object\nThread 6: success, dtype:\ntime    float32\ndtype: object\nThread 7: success, dtype:\ntime    float32\ndtype: object\n(tinyvit) jmt@jmtcluster:~/Projects/panama/panama-external$ python3 debug_multiprocessing.py \nPandera version:\n0.0.0+dev0\n=== Single Thread Validation ===\nBefore validation: time    float64\ndtype: object\nAfter validation: time    float32\ndtype: object\n\n=== Multithreaded Validation with ProgressParallel ===\nThread 0: success, dtype:\ntime    float32\ndtype: object\nThread 1: success, dtype:\ntime    float32\ndtype: object\nThread 2: success, dtype:\ntime    float32\ndtype: object\nThread 3: success, dtype:\ntime    float32\ndtype: object\nThread 4: error: expected series 'time' to have type float32, got float64\nThread 5: error: expected series 'time' to have type float32, got float64\nThread 6: error: expected series 'time' to have type float32, got float64\nThread 7: error: expected series 'time' to have type float32, got float64\n(tinyvit) jmt@jmtcluster:~/Projects/panama/panama-external$ python3 debug_multiprocessing.py \nPandera version:\n0.0.0+dev0\n=== Single Thread Validation ===\nBefore validation: time    float64\ndtype: object\nAfter validation: time    float32\ndtype: object\n\n=== Multithreaded Validation with ProgressParallel ===\nThread 0: success, dtype:\ntime    float32\ndtype: object\nThread 1: error: expected series 'time' to have type float32, got float64\nThread 2: error: expected series 'time' to have type float32, got float64\nThread 3: error: expected series 'time' to have type float32, got float64\nThread 4: success, dtype:\ntime    float32\ndtype: object\nThread 5: success, dtype:\ntime    float32\ndtype: object\nThread 6: success, dtype:\ntime    float32\ndtype: object\nThread 7: success, dtype:\ntime    float32\ndtype: object\n```\n#### Desktop (please complete the following information):\n\n - OS: Ubuntu 22.04\n\n","comments":[{"id":"IC_kwDOCUcGo86oQ96e","author":{"login":"RenaudLN"},"authorAssociation":"NONE","body":"I've just noticed the same issue, did you find a workaround?","createdAt":"2025-04-23T04:24:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2823020190","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86oSUIO","author":{"login":"JuanFMontesinos"},"authorAssociation":"NONE","body":"Hi,\r\nI'm afraid I did not. I simply deactivated multithreading with any\r\npandera-related ops.\r\n\r\nEl mié, 23 abr 2025 a las 6:25, Renaud Lainé ***@***.***>)\r\nescribió:\r\n\r\n> I've just noticed the same issue, did you find a workaround?\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2823020190>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AHXWLBSGMQ7CMODJKTFRWI3224I2PAVCNFSM6AAAAABY3STABCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDQMRTGAZDAMJZGA>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n> *RenaudLN* left a comment (unionai-oss/pandera#1940)\r\n> <https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2823020190>\r\n>\r\n> I've just noticed the same issue, did you find a workaround?\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2823020190>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AHXWLBSGMQ7CMODJKTFRWI3224I2PAVCNFSM6AAAAABY3STABCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDQMRTGAZDAMJZGA>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>\r\n","createdAt":"2025-04-23T07:46:05Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2823373326","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86oSe7t","author":{"login":"RenaudLN"},"authorAssociation":"NONE","body":"I traced the different calls through the code and the issue is that:\n* The schema object is [cached in the `MODEL_CACHE` global var](https://github.com/unionai-oss/pandera/blob/5a39bc1d218c7860afb544894bff08a05cdbefdb/pandera/api/dataframe/model.py#L212)\n* In `run_schema_component_checks`, [the `coerce` attribute of the columns is temporarily set to False](https://github.com/unionai-oss/pandera/blob/5a39bc1d218c7860afb544894bff08a05cdbefdb/pandera/backends/pandas/container.py#L206) before being [reset to its original value](https://github.com/unionai-oss/pandera/blob/5a39bc1d218c7860afb544894bff08a05cdbefdb/pandera/backends/pandas/container.py#L246) AND this impacts the globally cached schema!\n\nSo when a thread is doing `run_schema_component_checks` if another one starts the schema validation it can see a column with `coerce=False` when it should be `true`..\n\nLooks like something that should be fixed 🙂 \n","createdAt":"2025-04-23T08:04:32Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2823417581","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86oSvke","author":{"login":"RenaudLN"},"authorAssociation":"NONE","body":"The following workaround seems to be working for me: use `deepcopy(ToySchema.to_schema()).validate(...)` instead of `ToySchema.validate(...)`","createdAt":"2025-04-23T08:30:42Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2823485726","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86oku0b","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"@RenaudLN @JuanFMontesinos thanks for this bug report! Just pushed this PR, which should address this issue: https://github.com/unionai-oss/pandera/pull/1981","createdAt":"2025-04-24T16:24:04Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2828201243","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86omTKy","author":{"login":"JuanFMontesinos"},"authorAssociation":"NONE","body":"Thans to @RenaudLN  for debugging, glad to see the issue closed. \n","createdAt":"2025-04-24T19:08:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1940#issuecomment-2828612274","viewerDidAuthor":false}],"number":1940,"title":"Schema validation with coercion fails if using multithreading"},{"body":"**The difference**\n\nThe `__version__` of pandera installed from pip is \"0.0.0+dev0\".\n\n```python\nimport pandera as pa\n\nprint(pa.__version__)\n```\n\nWhile the pip list tells me:\npandera 0.23.1\n\nI would think of adding the version to the file pandera / version.py. But ideally it is either while building taken from there or written to there. With the idea to not repeat yourself.","comments":[],"number":1939,"title":"Set __version__"},{"body":"From Pandera v0.23.0, pa.Category and possibly other types, are resolving as 'any' in Pydantic core schema logic. However, this type doesn't exist in the type_map which then throws an exception. I don't fully understand the underlying logic and thus don't have an immediate solution to propose.\n\nhttps://github.com/unionai-oss/pandera/blob/ebbcaf20e1208d1b14ce44b03fe7b3301cd8e888/pandera/typing/pandas.py#L209\n\nReproducible example on Pandera v0.23.1:\n```python\nimport pydantic\nimport pandera as pa\nfrom pandera.typing.pandas import DataFrame\n\nclass MyPanderaModel(pa.DataFrameModel):\n    x: pa.Category = pa.Field(dtype_kwargs={'categories': ['a','b','c'], 'ordered': True})\n\nclass MyPydanticModel(pydantic.BaseModel):\n    df: DataFrame[MyPanderaModel]\n```\n\n```\nTraceback (most recent call last):\n  File \"test.py\", line 8, in <module>\n    class MyPydanticModel(pydantic.BaseModel):\n  File \".../python3.12/site-packages/pydantic/_internal/_model_construction.py\", line 224, in __new__\n    complete_model_class(\n  File \".../python3.12/site-packages/pydantic/_internal/_model_construction.py\", line 602, in complete_model_class\n    schema = cls.__get_pydantic_core_schema__(cls, handler)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/main.py\", line 702, in __get_pydantic_core_schema__\n    return handler(source)\n           ^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py\", line 84, in __call__\n    schema = self._handler(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 610, in generate_schema\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"...python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 879, in _generate_schema_inner\n    return self._model_schema(obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"...python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 691, in _model_schema\n    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 1071, in _generate_md_field_schema\n    common_field = self._common_field_schema(name, field_info, decorators)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 1263, in _common_field_schema\n    schema = self._apply_annotations(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 2056, in _apply_annotations\n    schema = get_inner_schema(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py\", line 84, in __call__\n    schema = self._handler(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 2037, in inner_handler\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 884, in _generate_schema_inner\n    return self.match_type(obj)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 986, in match_type\n    return self._match_generic_type(obj, origin)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 1007, in _match_generic_type\n    from_property = self._generate_schema_from_property(origin, obj)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \".../python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 759, in _generate_schema_from_property\n    schema = get_schema(\n             ^^^^^^^^^^^\n  File \".../python3.12/site-packages/pandera/typing/pandas.py\", line 209, in __get_pydantic_core_schema__\n    type_map[schema_json_columns[key][\"items\"][\"type\"]]\n    ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyError: 'any'\n```","comments":[],"number":1938,"title":"pa.Category resolving as 'any' in Pydantic core schema, which doesn't exist as a key in type_map"},{"body":"**Describe the bug**\nThe serialization of schemas to json or yaml serializes checks as a dict instead of a list. At runtime pandera uses a list. This has the problem, that when you have multiple checks that utilize the same check method, only the last defined instance of the check of a method is serialized (since the dict key is the method name). So if you have multiple checks that use the same check method but with different parameters, only one of those get serialized. This is especially a problem for checks on the whole dataframe.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [x] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport numpy as np\nimport pandera as pa\nimport pandera.extensions as extensions\n\n\n\n@extensions.register_check_method(statistics=['column_name', 'column_value', 'other_column_name', 'other_column_unset_value'])\ndef other_column_set_on_column_value(pandas_obj, *, column_name:str , column_value, other_column_name: str, other_column_unset_value):\n    return ~np.logical_and(pandas_obj[column_name]==column_value, pandas_obj[other_column_name]==other_column_unset_value)\n\n@extensions.register_check_method(statistics=['column_name', 'column_value', 'other_column_name', 'other_column_unset_value'])\ndef other_column_unset_on_column_value(pandas_obj, *, column_name, column_value, other_column_name: str, other_column_unset_value: int):\n    return ~np.logical_and(pandas_obj[column_name]!=column_value, pandas_obj[other_column_name]!=other_column_unset_value)\n\nschema = pa.DataFrameSchema(\n    columns={\n        'type': pa.Column(int, pa.Check.between(0,4, error=f\"Type must be one of ...\"), description=\"MovingObject.type\"),\n        'role': pa.Column(int, pa.Check.between(-1,10, error=f\"Role must be one of ...\")),\n        'subtype': pa.Column(int,  pa.Check.between(-1, 17, error=f\"Subtype must be one of...\"))},\n    checks=[\n        pa.Check.other_column_set_on_column_value(\n            'type', \n            2, \n            'role', \n            -1, \n            error=\"`role` is `-1` despite type beeing `TYPE_VEHICLE`\"),\n        pa.Check.other_column_unset_on_column_value(\n            'type', \n            2, \n            'role', \n            -1, \n            error=\"`role` is set despite type not beeing `TYPE_VEHICLE`\"),\n        pa.Check.other_column_set_on_column_value(\n            'type', \n            2, \n            'subtype', \n            -1, \n            error=\"`subtype` is `-1` despite type beeing `TYPE_VEHICLE`\"),\n        pa.Check.other_column_unset_on_column_value(\n            'type', \n            2, \n            'subtype', \n            -1, \n            error=\"`subtype` is set despite type not beeing `TYPE_VEHICLE`\"),\n    ])\n\nschema.to_json('schema.json')\nschema.to_yaml('schema.yaml')\n```\nschema.yaml\n```yaml\nschema_type: dataframe\nversion: 0.0.0+dev0\ncolumns:\n  type:\n    title: null\n    description: MovingObject.type\n    dtype: int64\n    nullable: false\n    checks:\n      in_range:\n        min_value: 0\n        max_value: 4\n        include_min: true\n        include_max: true\n        options:\n          raise_warning: false\n          ignore_na: true\n    unique: false\n    coerce: false\n    required: true\n    regex: false\n  role:\n    title: null\n    description: null\n    dtype: int64\n    nullable: false\n    checks:\n      in_range:\n        min_value: -1\n        max_value: 10\n        include_min: true\n        include_max: true\n        options:\n          raise_warning: false\n          ignore_na: true\n    unique: false\n    coerce: false\n    required: true\n    regex: false\n  subtype:\n    title: null\n    description: null\n    dtype: int64\n    nullable: false\n    checks:\n      in_range:\n        min_value: -1\n        max_value: 17\n        include_min: true\n        include_max: true\n        options:\n          raise_warning: false\n          ignore_na: true\n    unique: false\n    coerce: false\n    required: true\n    regex: false\nchecks:\n  other_column_set_on_column_value:\n    column_name: type\n    column_value: 2\n    other_column_name: subtype\n    other_column_unset_value: -1\n    options:\n      raise_warning: false\n      ignore_na: true\n  other_column_unset_on_column_value:\n    column_name: type\n    column_value: 2\n    other_column_name: subtype\n    other_column_unset_value: -1\n    options:\n      raise_warning: false\n      ignore_na: true\nindex: null\ndtype: null\ncoerce: false\nstrict: false\nname: null\nordered: false\nunique: null\nreport_duplicates: all\nunique_column_names: false\nadd_missing_columns: false\ntitle: null\ndescription: null\n\n```\n#### Expected behavior\nAll defined checks are listed in the schema. Currently those with same function name are overwritten.\n\n#### Desktop (please complete the following information):\n\n - OS: [e.g. iOS]\n - Browser: [e.g. chrome, safari]\n - Version: [e.g. 22]\n\n#### Screenshots\nIf applicable, add screenshots to help explain your problem.\n\n#### Additional context\nAdd any other context about the problem here.\n","comments":[],"number":1937,"title":"Serialization of checks does only support one check per check function"},{"body":"Python version: 3.11\npandera version: 0.23.0\n\nI am dealing with data in pandas DataFrames containing columns with array-like data and base types float, int, str, bool. Now I want to create a DataFrameSchema checking these columns, something like\n\n`'columnName', Column(array data type, ..., default=[])`\n\nCurrently, I use 'object') as data type, but this causes problems in certain cases. What is the right data type for these kind of data?\n\nI tried what is suggested in the [dtype validation documentation](https://pandera.readthedocs.io/en/stable/dtype_validation.html), but any variation led to an error:\n\n**First attempt:**\n\n```\nschema = DataFrameSchema(\n            {\n                'col1': Column(int, default=-1),\n                'col2': Column(float, nullable=True),\n                'col3': Column(bool, nullable=True),\n                ... more scalar columns\n                'ColumnWithArray1': Column(List[float]), <-------- !\n                'ColumnWithArray2': Column(object, nullable=True),\n                ... more columns scalar and array\n            }\n       )\n```\n\nLeads to:\n\n```\nFile \".../python3.11/site-packages/pandera/backends/pandas/container.py\", line 122, in validate\n    raise SchemaErrors(\npandera.errors.SchemaErrors: {\n    \"SCHEMA\": {\n        \"WRONG_DATATYPE\": [\n            {\n               {  All scalar type columns are listed here, not array/object type columns}\n```\n\n**Second attempt:**\n\n```\n...\n'ColumnWithArray1': Column(List[float], default=[]),\n'ColumnWithArray2': Column(object, nullable=True),\n...\n```\nException:\n\n```\nFile \".../python3.11/site-packages/pandera/backends/pandas/container.py\", line 554, in set_defaults\n    if (\nValueError: The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty.\n```\n**Third attempt**\n```\n...\n'ColumnWithArray1': Column(List[float], default=[]),\n'ColumnWithArray2': Column(object, nullable=True),\n...\n```\nException: same as first attempt\n\n**Fourth attempt**\n```\n...\n'ColumnWithArray1': Column(List[float], default=[1.0]),\n'ColumnWithArray2': Column(object, nullable=True),\n...\n```\nException:\n\n```\nFile \".../python3.11/site-packages/pandas/util/_validators.py\", line 299, in validate_fillna_kwargs\n    raise TypeError(\nTypeError: \"value\" parameter must be a scalar or dict, but you passed a \"list\"\n```","comments":[{"id":"IC_kwDOCUcGo86hFE7K","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"Hi @wolfig this looks like a bug. Do you mind sharing minimally reproducible code?","createdAt":"2025-03-06T01:05:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1935#issuecomment-2702462666","viewerDidAuthor":false},{"id":"IC_kwDOCUcGo86hKsN7","author":{"login":"wolfig"},"authorAssociation":"NONE","body":"Sure. I created a MinimalExample.py creating these errors together with two test data CSVs. In my tests, these exactly reproduce what I see.\nHowever, the problem/example is somewhat more complex than I described, I need to elaborate on this:\n* The scenario I am working in is a REST service providing data as JSON. I parse the JSON and create a DataFrame from it.\n* The Data from the REST service is coming in chunks as the REST service cannot provide Gigabytes of data in one go.\n* I write the chunked data as DataFrame by DataFrame to one parquet file by appending the file. This is by the way why I use a DataFrameSchema which creates missing columns on the fly when performing validation.\n* It can happen/happened to me that from chunk to chunk the columns contained in the JSON vary: in one chunk they are available in the next they are not or the other way around\n\n. This is what I try to simulate by providing 2 TestData files, one without the array-like column, one where the array-like column is \"switched on\" within the data table.\n\n[TestData1.csv](https://github.com/user-attachments/files/19109508/TestData1.csv)\n[TestData2.csv](https://github.com/user-attachments/files/19109509/TestData2.csv)\n\nTest code:\n\n```\nimport pandas as pd\nfrom pandera import Column, DataFrameSchema\nimport os\nimport traceback as tb\n\n\ndef get_schema_1():\n    schema = DataFrameSchema(\n        {\n            'intColumn': Column(int, default=-1),\n            'floatColumn': Column(float, nullable=True),\n            'boolColumn': Column(bool, nullable=True),\n            'strColumn': Column(str, nullable=True),\n            'listColumn': Column(list[float], nullable=True)\n        }\n        , name='my_schema'\n        , drop_invalid_rows=False\n        , coerce=True\n        , add_missing_columns=True\n        , unique_column_names=True\n    )\n\n    return schema\n\n\ndef get_schema_2():\n    schema = DataFrameSchema(\n        {\n            'intColumn': Column(int, default=-1),\n            'floatColumn': Column(float, nullable=True),\n            'boolColumn': Column(bool, nullable=True),\n            'strColumn': Column(str, nullable=True),\n            'listColumn': Column(list[float], default=[])\n        }\n        , name='my_schema'\n        , drop_invalid_rows=False\n        , coerce=True\n        , add_missing_columns=True\n        , unique_column_names=True\n    )\n\n    return schema\n\ndef get_schema_3():\n    schema = DataFrameSchema(\n        {\n            'intColumn': Column(int, default=-1),\n            'floatColumn': Column(float, nullable=True),\n            'boolColumn': Column(bool, nullable=True),\n            'strColumn': Column(str, nullable=True),\n            'listColumn': Column(list[float], default=[1.0])\n        }\n        , name='my_schema'\n        , drop_invalid_rows=False\n        , coerce=True\n        , add_missing_columns=True\n        , unique_column_names=True\n    )\n\n    return schema\n\nif __name__ == '__main__':\n    try:\n        test_data = pd.read_csv('TestData1.csv', delimiter=';')\n        validated_data = get_schema_1().validate(test_data)\n        validated_data.to_parquet('output1.parquet', engine='fastparquet', append=os.path.isfile('output1.parquet'))\n    except Exception as err:\n        print('[ERROR] Schema 1: Validating/Writing TestData1  creating output1 failed.')\n        tb.print_exc()\n        pass\n\n    try:\n        test_data = pd.read_csv('TestData2.csv', delimiter=';')\n        validated_data = get_schema_1().validate(test_data)\n        validated_data.to_parquet('output1.parquet', engine='fastparquet', append=os.path.isfile('output1.parquet'))\n    except Exception as err:\n        print('[ERROR] Schema 1: Validating/Writing TestData2 appending output1 failed.')\n        tb.print_exc()\n        pass\n\n    try:\n        test_data = pd.read_csv('TestData1.csv', delimiter=';')\n        validated_data = get_schema_2().validate(test_data)\n        validated_data.to_parquet('output2.parquet', engine='fastparquet', append=os.path.isfile('output2.parquet'))\n    except Exception as err:\n        print('[ERROR] Schema 2: Validating/Writing TestData2  creating output2 failed.')\n        tb.print_exc()\n        pass\n\n    try:\n        test_data = pd.read_csv('TestData2.csv', delimiter=';')\n        validated_data = get_schema_2().validate(test_data)\n        validated_data.to_parquet('output2.parquet', engine='fastparquet', append=os.path.isfile('output2.parquet'))\n    except Exception as err:\n        print('[ERROR] Schema 2: Validating/Writing TestData2 appending output2 failed.')\n        tb.print_exc()\n        pass\n\n    try:\n        test_data = pd.read_csv('TestData1.csv', delimiter=';')\n        validated_data = get_schema_3().validate(test_data)\n        validated_data.to_parquet('output3.parquet', engine='fastparquet', append=os.path.isfile('output3.parquet'))\n    except Exception as err:\n        print('[ERROR] Schema 3: Validating/Writing TestData1  creating output3 failed.')\n        tb.print_exc()\n        pass\n\n    try:\n        test_data = pd.read_csv('TestData2.csv', delimiter=';')\n        validated_data = get_schema_3().validate(test_data)\n        validated_data.to_parquet('output3.parquet', engine='fastparquet', append=os.path.isfile('output3.parquet'))\n    except Exception as err:\n        print('[ERROR] Schema 3: Validating/Writing TestData2 appending output3 failed.')\n        tb.print_exc()\n        pass\n```","createdAt":"2025-03-06T14:00:21Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1935#issuecomment-2703934331","viewerDidAuthor":false}],"number":1935,"title":"Pandera DataFrameSchema Column definition with array"},{"body":"If you attempt to add additional args onto a @pa.dataframe_check they don't get passed threw to the underlying class method.\n\n```\nclass BugTestSchema(pa.DataFrameModel):\n    @pa.dataframe_check(env=DataLakeEnv.prod)\n    def check_counterparty_combinations(cls, df, env: DataLakeEnv) -> Series[bool]:\n        valid_combinations = get_counterparty_payment_terms(env=env)\n        ...\n```\n\n\"error\": \"Error while executing check function: TypeError(\\\"BaseCheckInfo.to_check.<locals>._adapter() got an unexpected keyword argument 'env'\\\")\n\nThere's some dynamic values testing that we're doing and at least being able to pass threw check_kwargs gets us the minimal functionality we need.\n\nBugfix PR to follow with a fix","comments":[],"number":1933,"title":"@pa.dataframe_check doesn't actually support its check_kwargs"},{"body":"**Describe the bug**\nA clear and concise description of what the bug is.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [x] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandera as pa\nimport polars as pl\npa.Column(pl.Int64)\n```\n\n#### Expected behavior\nIt should run without error, as suggested in official doc: https://pandera.readthedocs.io/en/latest/polars.html#supported-data-types\n\n#### Desktop (please complete the following information):\n\n - OS: [e.g. Ubuntu]\n - Browser: [e.g. chrome]\n - Version: [23]\n\n#### Screenshots\nIt tries to understand the dtype using Pandas engine, causing error of course.\n```\n>>> pa.Column(pl.Int64)\nTraceback (most recent call last):\n  File \"/storage/repos/pandera/verytemp/.venv/lib/python3.12/site-packages/pandera/engines/pandas_e\nngine.py\", line 234, in dtype\n    return engine.Engine.dtype(cls, data_type)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/storage/repos/pandera/verytemp/.venv/lib/python3.12/site-packages/pandera/engines/engine.p\ny\", line 271, in dtype\n    raise TypeError(\nTypeError: Data type 'Int64' not understood by Engine.\n```\n\n\n","comments":[{"id":"IC_kwDOCUcGo86gxKHI","author":{"login":"deephbz"},"authorAssociation":"NONE","body":"It's actually `import pandera.polars as pa`. User error","createdAt":"2025-03-04T11:39:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/unionai-oss/pandera/issues/1932#issuecomment-2697241032","viewerDidAuthor":false}],"number":1932,"title":"Polars support breaks: Basic `pa.Column()` does not support Polars dtypes at all"},{"body":"In Pandera v0.22.x the below definition of a Pydantic model that includes a Pandera dataframe model with a default value works fine, but as of v0.23 it fails with an error.  If the `Any` is changed to `int` or some other specific data type, the error goes away, but in our application there's one column that's a freeform type.\n\n- [x] I have checked that this issue has not already been reported.\n- [x] I have confirmed this bug exists on the latest version of pandera.\n- [ ] (optional) I have confirmed this bug exists on the main branch of pandera.\n\n**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\n\n#### Code Sample, a copy-pastable example\n\n```python\nimport pandera as pr\nfrom pydantic import BaseModel\nfrom typing import Any\nimport pandas as pd\n\nclass PudlCodeMetadata(BaseModel):\n    \"\"\"Describes a bunch of codes.\"\"\"\n\n    class CodeDataFrame(pr.DataFrameModel):\n        \"\"\"The DF we use to represent code/label/description associations.\"\"\"\n\n        code: pr.typing.Series[Any]\n\n    df: pr.typing.DataFrame[CodeDataFrame] = pd.DataFrame(\n        {\"code\": [1, 2, 3]}\n    )\n```\n\n\n#### Expected behavior\nExpected the Pydantic class definition to succeed on import.\n\n#### Desktop (please complete the following information):\n\n - OS: MacOS 15\n - Browser: Firefox v135\n - Version: Pandera v0.23\n\n#### Additional context\n\n<details>\n<summary>\nFull stack trace from import failure\n</summary>\n\n\n```\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/Users/zane/code/catalyst/pudl/src/pudl/__init__.py\", line 5, in <module>\n    from . import (\n  File \"/Users/zane/code/catalyst/pudl/src/pudl/analysis/__init__.py\", line 9, in <module>\n    from . import (\n  File \"/Users/zane/code/catalyst/pudl/src/pudl/analysis/allocate_gen_fuel.py\", line 145, in <module>\n    from pudl.metadata.fields import apply_pudl_dtypes\n  File \"/Users/zane/code/catalyst/pudl/src/pudl/metadata/__init__.py\", line 3, in <module>\n    from . import (\n  File \"/Users/zane/code/catalyst/pudl/src/pudl/metadata/classes.py\", line 1075, in <module>\n    class PudlResourceDescriptor(PudlMeta):\n  File \"/Users/zane/code/catalyst/pudl/src/pudl/metadata/classes.py\", line 1105, in PudlResourceDescriptor\n    class PudlCodeMetadata(PudlMeta):\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py\", line 224, in __new__\n    complete_model_class(\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py\", line 602, in complete_model_class\n    schema = cls.__get_pydantic_core_schema__(cls, handler)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/main.py\", line 702, in __get_pydantic_core_schema__\n    return handler(source)\n           ^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py\", line 84, in __call__\n    schema = self._handler(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 610, in generate_schema\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 879, in _generate_schema_inner\n    return self._model_schema(obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 691, in _model_schema\n    {k: self._generate_md_field_schema(k, v, decorators) for k, v in fields.items()},\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 1071, in _generate_md_field_schema\n    common_field = self._common_field_schema(name, field_info, decorators)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 1263, in _common_field_schema\n    schema = self._apply_annotations(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 2056, in _apply_annotations\n    schema = get_inner_schema(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py\", line 84, in __call__\n    schema = self._handler(source_type)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 2037, in inner_handler\n    schema = self._generate_schema_inner(obj)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 884, in _generate_schema_inner\n    return self.match_type(obj)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 986, in match_type\n    return self._match_generic_type(obj, origin)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 1007, in _match_generic_type\n    from_property = self._generate_schema_from_property(origin, obj)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py\", line 759, in _generate_schema_from_property\n    schema = get_schema(\n             ^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pandera/typing/pandas.py\", line 193, in __get_pydantic_core_schema__\n    schema_json_columns = schema_model.to_json_schema()[\"properties\"]\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/zane/miniforge3/envs/pudl-dev/lib/python3.12/site-packages/pandera/api/pandas/model.py\", line 210, in to_json_schema\n    {k: v.type for k, v in schema.dtypes.items()}\n        ^^^^^^\nAttributeError: 'NoneType' object has no attribute 'type'\n```\n\n</details>\n","comments":[{"id":"IC_kwDOCUcGo86gp4ds","author":{"login":"cosmicBboy"},"authorAssociation":"COLLABORATOR","body":"Probably due to https://github.com/unionai-oss/pandera/pull/1904, will need to handle the `Any` case somehow","createdAt":"2025-03-03T19:22:08Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/unionai-oss/pandera/issues/1930#issuecomment-2695333740","viewerDidAuthor":false}],"number":1930,"title":"In pandera v0.23 DataFrameModel with column of type Any breaks Pydantic model"}]
